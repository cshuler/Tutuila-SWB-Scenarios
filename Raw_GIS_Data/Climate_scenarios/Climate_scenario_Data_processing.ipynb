{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook takes in netCDF based climate model preditions and formats them for use in the SWB model \n",
    "Some notes: \n",
    "- The projection on these files seems messed up. Therefore I had to manually move them over somewhat to line them up with what I estimated to be the right spot\n",
    "- So far I have only done rainfall. If I wanted to do temperature too I would fhave to do the temp max and min..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 85%; }\n",
       "    div#maintoolbar-container { width: 99%; } </style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make the screen bigger!\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(data=\"\"\" <style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 85%; }\n",
    "    div#maintoolbar-container { width: 99%; } </style> \"\"\"))\n",
    "\n",
    "# modules\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from pyproj import Proj, transform\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# functions \n",
    "def writeArrayToArcGrid(arr,filename,xll,yll,cellsize,no_data_val):\n",
    "    \"\"\" this takes a 2d numpy array and turns it into an .asc file \"\"\"\n",
    "    arr                = np.copy(arr)\n",
    "    arr[np.isnan(arr)] = no_data_val\n",
    "    headerstring       = bytes('NCOLS %d\\nNROWS %d\\nXLLCENTER %f\\nYLLCENTER %f\\nCELLSIZE %f\\nNODATA_value %f\\n' % \n",
    "        (arr.shape[1], arr.shape[0], xll, yll, cellsize, no_data_val), 'UTF-8')\n",
    "\n",
    "    with open(filename,'wb') as fout:\n",
    "        fout.write(headerstring)\n",
    "        np.savetxt(fout,arr,'%5.2f')\n",
    "        \n",
    "# Paths\n",
    "Datapath = os.path.join(\".\", 'RawData')\n",
    "Outpath =  os.path.join(\".\", 'ProcessedData')\n",
    "\n",
    "Rain_present = Datapath +'\\\\'+'samoa_hourly_present_RAIN_1990-2009.nc'\n",
    "Rain_rcp45 = Datapath +'\\\\'+'samoa_hourly_rcp45_RAIN_1990-2009.nc'\n",
    "Rain_rcp85 = Datapath +'\\\\'+'samoa_hourly_rcp85_RAIN_1990-2009.nc'\n",
    "\n",
    "Temp_present = Datapath +'\\\\'+'samoa_hourly_present_T2_1990-2009.nc'\n",
    "Temp_rcp45 = Datapath +'\\\\'+'samoa_hourly_rcp45_T2_1990-2009.nc'\n",
    "Temp_rcp85 = Datapath +'\\\\'+'samoa_hourly_rcp85_T2_1990-2009.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load up all the rainfall data files \n",
    "\n",
    "data_R_p = xr.open_dataset(Rain_present)    # open up the nc file\n",
    "data_R_45 = xr.open_dataset(Rain_rcp45)    \n",
    "data_R_85 = xr.open_dataset(Rain_rcp85)    \n",
    "\n",
    "rain_variable_R_p = data_R_p['RAIN']            # select the rain variable (has time, lat and lon dimentions)\n",
    "rain_variable_R_45 = data_R_45['RAIN']  \n",
    "rain_variable_R_85 = data_R_85['RAIN']  \n",
    "\n",
    "#monthly_R_p = rain_variable.groupby('Time.month').sum(dim='Time')   # turn it into a set of 12 time arrays one for each month (all 20 years of data ADDED together for each month) \n",
    "#monthly_R_p = monthly/20    # this is because the dataset is 20 years long, now er have average monthly values from the 20 year dataset, but for one month\n",
    "\n",
    "yearly_R_p = rain_variable_R_p.groupby('Time.year').sum(dim='Time')    # turn it into 20 time arrays one for each year\n",
    "yearly_R_45 = rain_variable_R_45.groupby('Time.year').sum(dim='Time')\n",
    "yearly_R_85 = rain_variable_R_85.groupby('Time.year').sum(dim='Time')\n",
    "\n",
    "yearlyave_R_p = np.mean(yearly_R_p, 0)                                 # Average all the years together into a single average yearly dataset\n",
    "yearlyave_R_45 = np.mean(yearly_R_45, 0) \n",
    "yearlyave_R_85 = np.mean(yearly_R_85, 0) \n",
    "\n",
    "#yearlyave_R_p.plot(); plt.show()            # plot if want\n",
    "#yearlyave_R_45.plot() ; plt.show()\n",
    "#yearlyave_R_85.plot() ; plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rainfall Data Yearly loop, also this defines some of the geometry attributes used in the monthly ones so need to run first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_list = [yearlyave_R_p,  yearlyave_R_45,  yearlyave_R_85]     # list of the processed yearly average arrays from above\n",
    "name_list = [\"present\", \"rcp45\", \"rcp85\"]                          # names \n",
    "\n",
    "# this little block does some projection from WGS 84 to UTM2  but just for getting the corner values really, \n",
    "# projection definitions\n",
    "inProj = Proj(\"+proj=latlon +ellps=WGS84 + datum=WGS84 +no_defs +towgs84=0,0,0\")\n",
    "outProj = Proj(\"+proj=utm +zone=2 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs \")\n",
    "LonData = np.array(data_R_p['XLONG']).flatten()\n",
    "LatData = np.array(data_R_p['XLAT']).flatten()\n",
    "LonDataUTM, LatDataUTM = transform(inProj, outProj, LonData , LatData)\n",
    "MaxY = round(max(LatDataUTM))\n",
    "MinY = round(min(LatDataUTM))\n",
    "MaxX = round(max(LonDataUTM))\n",
    "MinX = round(min(LonDataUTM))\n",
    "Lx = MaxX - MinX\n",
    "Ly = MaxY - MinY\n",
    "Dy = Lx/50\n",
    "Dx = Ly/26\n",
    "XLLCORNER =  MinX+2800        # so the projection of the NETCDF file seems to be messed up. I Substituted these numbers in to transform it to more reasonable values\n",
    "YLLCORNER = MinY+400\n",
    "\n",
    "# this then writes the array to an asc file\n",
    "for ix in range(0,3):    \n",
    "    Why_upsidedown = np.flip(scene_list[ix], axis=0)\n",
    "    writeArrayToArcGrid(Why_upsidedown*0.0393701, os.path.join(Outpath,  \"yearly_rainfall_{}.asc\".format(name_list[ix])), XLLCORNER, YLLCORNER, 800, -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rainfall Monthly Loop \n",
    "same as above but loops over each month to create monthyl files which the model will actually use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = rain_variable_R_p.groupby('Time.month').sum(dim='Time')   # turn it into a set of 12 time arrays one for each month (all 20 years of data ADDED together for each month) \n",
    "monthly_R_p = monthly/20    # this is because the dataset is 20 years long, now er have average monthly values from the 20 year dataset, but for one month\n",
    "\n",
    "monthly = rain_variable_R_45.groupby('Time.month').sum(dim='Time')   # turn it into a set of 12 time arrays one for each month (all 20 years of data ADDED together for each month) \n",
    "monthly_R_45 = monthly/20\n",
    "\n",
    "monthly = rain_variable_R_85.groupby('Time.month').sum(dim='Time')   # turn it into a set of 12 time arrays one for each month (all 20 years of data ADDED together for each month) \n",
    "monthly_R_85 = monthly/20\n",
    "\n",
    "scene_list = [monthly_R_p,  monthly_R_45,  monthly_R_85]\n",
    "Data_list = [data_R_p,  data_R_45,  data_R_85] \n",
    "name_list = [\"present\", \"rcp45\", \"rcp85\"]\n",
    "\n",
    "for ix in range(0,3):  \n",
    "    Why_upsidedown = scene_list[ix]\n",
    "    \n",
    "    for mo in range(1,13):       \n",
    "        writeArrayToArcGrid(np.flip(Why_upsidedown[mo-1]*0.0393701, axis=0), os.path.join(Outpath,  \"month_{}_rainfall_{}.asc\".format(mo, name_list[ix])), XLLCORNER, YLLCORNER, 800, -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# craycray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp Data preparation\n",
    "data_T_p = xr.open_dataset(Temp_present)    # open up the nc file\n",
    "data_T_45 = xr.open_dataset(Temp_rcp45)    \n",
    "data_T_85 = xr.open_dataset(Temp_rcp85)  \n",
    "\n",
    "temp_variable_T_p = data_T_p['T2']            # select the rain variable (has time, lat and lon dimentions)\n",
    "temp_variable_T_45 = data_T_45['T2']  \n",
    "temp_variable_T_85 = data_T_85['T2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# holy moly this works!  But it takes forrrreeeevvvvoooorrrrrrrrrrrrrrrrrrrrrrrrrrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thise load up each file and find the daily max and min hour sets then compile them into a monthly average resolution, then further take the average of each month\n",
    "\n",
    "# present Min\n",
    "DailyminT = temp_variable_T_p.resample(Time=\"D\").min(dim='Time')\n",
    "Month_minT = DailyminT.resample(Time=\"M\").mean(dim='Time')\n",
    "Fin_Month_minT = Month_minT.groupby('Time.month').mean(dim='Time') \n",
    "Fin_Month_minT.to_netcdf(os.path.join('.', \"Month_minT_present.nc\"))\n",
    "\n",
    "# present Max\n",
    "DailymaxT = temp_variable_T_p.resample(Time=\"D\").max(dim='Time')\n",
    "Month_maxT = DailymaxT.resample(Time=\"M\").mean(dim='Time')\n",
    "Fin_Month_maxT = Month_maxT.groupby('Time.month').mean(dim='Time') \n",
    "Fin_Month_maxT.to_netcdf(os.path.join('.', \"Month_maxT_present.nc\"))\n",
    "\n",
    "# rcp45 Min\n",
    "DailyminT45 = temp_variable_T_45.resample(Time=\"D\").min(dim='Time')\n",
    "Month_minT_45 = DailyminT45.resample(Time=\"M\").mean(dim='Time')\n",
    "Fin_Month_minT_45 = Month_minT_45.groupby('Time.month').mean(dim='Time') \n",
    "Fin_Month_minT_45.to_netcdf(os.path.join('.', \"Month_min_45.nc\"))\n",
    "\n",
    "# rcp45 Max\n",
    "DailymaxT45 = temp_variable_T_45.resample(Time=\"D\").max(dim='Time')\n",
    "Month_maxT_45 = DailymaxT45.resample(Time=\"M\").mean(dim='Time')\n",
    "Fin_Month_maxT_45 = Month_maxT_45.groupby('Time.month').mean(dim='Time') \n",
    "Fin_Month_maxT_45.to_netcdf(os.path.join('.', \"Month_maxT_45.nc\"))\n",
    "\n",
    "# rcp85 Min\n",
    "DailyminT85 = temp_variable_T_85.resample(Time=\"D\").min(dim='Time')\n",
    "Month_minT_85 = DailyminT85.resample(Time=\"M\").mean(dim='Time')\n",
    "Fin_Month_minT_85 = Month_minT_85.groupby('Time.month').mean(dim='Time') \n",
    "Fin_Month_minT_85.to_netcdf(os.path.join('.', \"Month_min_85.nc\"))\n",
    "\n",
    "# rcp85 Max\n",
    "DailymaxT85 = temp_variable_T_85.resample(Time=\"D\").max(dim='Time')\n",
    "Month_maxT_85 = DailymaxT85.resample(Time=\"M\").mean(dim='Time')\n",
    "Fin_Month_maxT_85 = Month_maxT_85.groupby('Time.month').mean(dim='Time') \n",
    "Fin_Month_maxT_85.to_netcdf(os.path.join('.', \"Month_maxT_85.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2C = 273.15            # conversion factor from kelvin to C\n",
    "\n",
    "MAXscene_list = [Fin_Month_maxT,  Fin_Month_maxT_45,  Fin_Month_maxT_85]\n",
    "MINscene_list = [Fin_Month_minT,  Fin_Month_minT_45,  Fin_Month_minT_85]\n",
    "\n",
    "for ix in range(0,3):  \n",
    "    Why_upsidedown = MAXscene_list[ix]\n",
    "    \n",
    "    for mo in range(1,13):       \n",
    "        writeArrayToArcGrid(np.flip(Why_upsidedown[mo-1]-K2C, axis=0), os.path.join(Outpath,  \"month_{}_maxTemp_{}.asc\".format(mo, name_list[ix])), XLLCORNER, YLLCORNER, 800, -999)\n",
    "\n",
    "for ix in range(0,3):  \n",
    "    Why_upsidedown = MINscene_list[ix]\n",
    "    \n",
    "    for mo in range(1,13):       \n",
    "        writeArrayToArcGrid(np.flip(Why_upsidedown[mo-1]-K2C, axis=0), os.path.join(Outpath,  \"month_{}_minTemp_{}.asc\".format(mo, name_list[ix])), XLLCORNER, YLLCORNER, 800, -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes forever dont run it\n",
    "dayminlist = []\n",
    "for i in range (0, 7305):   # 7305 is number of days in 20 years\n",
    "    if  i/100 == int(i/100):\n",
    "        print(i)\n",
    "    step = 24*i\n",
    "    day_arr = temp_variable_T_p[0+step:24+step,:,:]\n",
    "    day_min = day_arr.groupby('Time.day').min(dim='Time')\n",
    "    dayminlist.append(day_min)\n",
    "    \n",
    "daily_min =  xr.concat(dayminlist, dim='day')\n",
    "daily_min.to_netcdf(os.path.join('.', \"Daily_min_temp_present.nc\"), encoding={'day':{'units':'days since 1900-01-01'}})\n",
    "\n",
    "\n",
    "daymaxlist = []\n",
    "for i in range (0, 7305):   # 7305 is number of days in 20 years\n",
    "    if  i/100 == int(i/100):\n",
    "        print(i)\n",
    "    step = 24*i\n",
    "    day_arr = temp_variable_T_p[0+step:24+step,:,:]\n",
    "    day_max = day_arr.groupby('Time.day').max(dim='Time')\n",
    "    daymaxlist.append(day_max)\n",
    "    \n",
    "daily_max =  xr.concat(daymaxlist, dim='day')\n",
    "daily_max.to_netcdf(os.path.join('.', \"Daily_max_temp_present.nc\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
