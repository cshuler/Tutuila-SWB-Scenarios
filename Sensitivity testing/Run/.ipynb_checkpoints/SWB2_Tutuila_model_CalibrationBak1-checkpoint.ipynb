{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_et total  221019.0 [m3/d]\n",
      "direct_net_infiltation total  36247.6 [m3/d]\n",
      "direct_soil_moisture total  1944.4 [m3/d]\n",
      "interception total  127397.1 [m3/d]\n",
      "net_infiltration total  909699.3 [m3/d]\n",
      "rainfall total  1486348.1 [m3/d]\n",
      "runoff total  277173.3 [m3/d]\n",
      "WATER BALANCE ratio: outs over ins water budget balanece =  1.0096134155207488 % \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFR leo in MGD is 1.2435263472140021\n",
      "MFR taf in MGD is 5.23504963553931\n",
      "MFR total in MGD is 6.478575982753312\n",
      "actual_et total  221019.0 [m3/d]\n",
      "direct_net_infiltation total  54222.5 [m3/d]\n",
      "direct_soil_moisture total  1944.4 [m3/d]\n",
      "interception total  127397.1 [m3/d]\n",
      "net_infiltration total  927674.3 [m3/d]\n",
      "rainfall total  1486348.1 [m3/d]\n",
      "runoff total  277173.3 [m3/d]\n",
      "WATER BALANCE ratio: outs over ins water budget balanece =  1.0095012487368313 % \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\arcgis\\pro\\Resources\\ArcToolbox\\Scripts\\AddGeometryAttributes.py:412: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#### import modules\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import os\n",
    "import sys\n",
    "from arcpy.sa import *\n",
    "import pandas as pd\n",
    "#import gdal\n",
    "from arcpy import env\n",
    "import shutil\n",
    "import numpy.ma as ma\n",
    "import netCDF4 as nc\n",
    "import subprocess\n",
    "import re\n",
    "%matplotlib notebook\n",
    "# this is a list of additional functions to load up, as to not clutter the script\n",
    "%run ../../Std_input/COMMON/plot_and_table_functions\n",
    "\n",
    "# set properties\n",
    "arcpy.env.overwriteOutput = True # make sure overwrite files is on\n",
    "# projection definition \n",
    "sr_project = arcpy.SpatialReference(32702)   # Project dataset into WGS84\n",
    "cel_size = 100     # in m \n",
    "Control_File_Name = 'Tutuila_cal_controlFile.ctl'\n",
    "\n",
    "\n",
    "#### General coverages and paths. More, basic model setup.\n",
    "GIS_FOLDER = os.path.join('..', '..', 'Raw_GIS_Data')\n",
    "STD_INPUT_FOLDER = os.path.join('..', '..', 'Std_input')\n",
    "# path to the grid bound\n",
    "Grid_shp = os.path.join(GIS_FOLDER, 'grid_bound.shp')\n",
    "\n",
    "if not os.path.exists(os.path.join('..', 'output//')):\n",
    "    os.makedirs(os.path.join('..', 'output//'))\n",
    "                        \n",
    "        \n",
    "input_folder = os.path.join(\"..\", \"..\", \"Model_workspace\", \"input\") \n",
    "\n",
    "# Move in other standard input files and modify control file to the shape of the current run\n",
    "# modify the control file grid for the given run   (note this uses dimensions from the rainfall adjustment grid in april)\n",
    "with open(os.path.join(input_folder, 'RF_adj_grids', 'rfadj_apr.asc'), 'r') as dims_file:   # open an ASC file and get the dimenstions out of it \n",
    "    dimsfile1 = dims_file.read().splitlines(True)\n",
    "    x_dim = float(re.findall('\\d+', dimsfile1[0])[-1])    \n",
    "    y_dim = float(re.findall('\\d+', dimsfile1[1])[-1])\n",
    "\n",
    "with open(os.path.join('.', Control_File_Name), 'r') as fin:   # open file \n",
    "    data = fin.read().splitlines(True)\n",
    "with open(os.path.join('.', Control_File_Name), 'w') as fout:     # delete first line\n",
    "    fout.writelines(data[1:])\n",
    "new_first = 'GRID {} {} 515000. 8409000. {} '.format(x_dim, y_dim, cel_size)  # new first line \n",
    "with open(os.path.join('.', Control_File_Name), 'r+') as file:                # add in new first line and save file  \n",
    "    file_data = file.read()\n",
    "    file. seek(0, 0)\n",
    "    file. write(new_first + '\\n' + file_data)\n",
    "\n",
    "# land use lookup file\n",
    "shutil.copy2(os.path.join(STD_INPUT_FOLDER, 'Landuse_lookup_maui_mod5.txt') ,os.path.join(input_folder))    \n",
    "\n",
    "# Simple RO : RF ratios file\n",
    "shutil.copy2(os.path.join(GIS_FOLDER, 'Runofftorainfall2\\\\RO_Rf_ratios_real_monthly3_2000_2010.txt') ,os.path.join(input_folder)) # note this is from the simplified version with zone IDs starting at 1\n",
    "\n",
    "# Rain Fragments file\n",
    "shutil.copy2(os.path.join(STD_INPUT_FOLDER, \"Fragments\", 'Rainfall_fragments_2001.prn') ,os.path.join(input_folder))  \n",
    "\n",
    "#  Fragments sequence file\n",
    "shutil.copy2(os.path.join(STD_INPUT_FOLDER, \"Fragments\", 'Sequence_file_2002.prn') ,os.path.join(input_folder)) \n",
    "\n",
    "# need to run this before the 1st model run to re-fresh the direct net infiltration coverage to not include the MFR. \n",
    "arcpy.Plus_3d(os.path.join(input_folder,  'Direct_infiltration',  \"A_WL_Rast.asc\"), os.path.join(input_folder,  'Direct_infiltration', \"OSDS_inlf_in.asc\"), os.path.join(input_folder,  'Direct_infiltration', \"temprast\"))\n",
    "arcpy.RasterToASCII_conversion(os.path.join(input_folder,  'Direct_infiltration', \"temprast\"), os.path.join(input_folder,  'Direct_infiltration', \"Total_inlf_in.asc\"))\n",
    "\n",
    "\n",
    "# RUN Da MODEL (with no MFR) \n",
    "os.chdir(os.path.join(\"..\", \"run\"))\n",
    "# Executable and control file copies\n",
    "shutil.copy2(os.path.join(\".\" , 'swb2.exe') ,os.path.join('..', 'output')) \n",
    "shutil.copy2(os.path.join(\".\" , Control_File_Name) ,os.path.join('..', 'output')) \n",
    "\n",
    "os.chdir(os.path.join(\"..\", \"output\"))\n",
    "subprocess.call('swb2.exe {}'.format(Control_File_Name), shell=True)\n",
    "os.chdir(os.path.join(\"..\", \"run\"))\n",
    "\n",
    "### Post process da files\n",
    "outspace = os.path.join('..', \"output\", 'post_prcessed_no_MFR')\n",
    "if not os.path.exists(outspace):\n",
    "    os.makedirs(outspace)\n",
    "    \n",
    "# Parameters\n",
    "Desired_files = ['actual_et',  'direct_net_infiltation', 'direct_soil_moisture',\n",
    "             'interception', 'net_infiltration', 'rainfall', 'runoff'] # 'delta_soil_storage',  'irrigation', \n",
    "XLLCORNER =      515000.000\n",
    "YLLCORNER =      8409000.000\n",
    "CELLSIZE  =      cel_size\n",
    "\n",
    "# functions\n",
    "def create_file_reference( component_name ):\n",
    "    '''\n",
    "    This is a simple convenience function that will form a path and filename to a\n",
    "    given water budget component\n",
    "    '''\n",
    "    # specify the prefix, path to SWB2 output, timeframe, and resolution\n",
    "    #output_path = os.path.join(os.getcwd(), \"output\")\n",
    "    #prefix      = '\\\\'\n",
    "    start_year  = '2000-01-01'\n",
    "    end_year    = '2009-12-31'\n",
    "    ncol        = str(int(x_dim))\n",
    "    nrow        = str(int(y_dim))\n",
    "    return(  component_name + '__' + start_year + '_' \n",
    "          + end_year + '__' + nrow + '_by_' + ncol + '.nc' )\n",
    "\n",
    "# some other functions to post process stuff\n",
    "\n",
    "def ncdump(nc_fid):\n",
    "    '''ncdump outputs dimensions, variables and their attribute information of netCDF4 files'''\n",
    "    nc_attrs = nc_fid.ncattrs()\n",
    "    nc_dims = [dim for dim in nc_fid.dimensions]  \n",
    "    nc_vars = [var for var in nc_fid.variables] \n",
    "    return nc_attrs, nc_dims, nc_vars\n",
    "\n",
    "def writeArrayToArcGrid(arr,filename,xll,yll,cellsize,no_data_val):\n",
    "    \"\"\" this takes a 2d numpy array and turns it into an .asc file \"\"\"\n",
    "    arr                = np.copy(arr)\n",
    "    arr[np.isnan(arr)] = no_data_val\n",
    "    headerstring       = bytes('NCOLS %d\\nNROWS %d\\nXLLCENTER %f\\nYLLCENTER %f\\nCELLSIZE %f\\nNODATA_value %f\\n' % \n",
    "        (arr.shape[1], arr.shape[0], xll, yll, cellsize, no_data_val), 'UTF-8')\n",
    "\n",
    "    with open(filename,'wb') as fout:\n",
    "        fout.write(headerstring)\n",
    "        np.savetxt(fout,arr,'%5.2f')\n",
    "        \n",
    "\n",
    "# post process the whole model domain\n",
    "os.chdir(os.path.join(\"..\", 'output'))  # difficulty in making the path to the file so need to change into the output directory\n",
    "var = []; tot = []; nclist = []\n",
    "\n",
    "# Step 1: make list of files that you wish to process \n",
    "for i in Desired_files:\n",
    "    Da_file = create_file_reference(i)\n",
    "    nclist.append(Da_file)\n",
    "    \n",
    "# Step 2 average the daily dimension (len(t) is # of days in the run) to annual \n",
    "for i, f in enumerate(nclist):\n",
    "    nc_data = nc.Dataset(nclist[i])\n",
    "    nc_attrs, nc_dims, nc_vars = ncdump(nc_data)\n",
    "    nc_var = nc_vars[3]\n",
    "    t = nc_data.variables['time'][:]\n",
    "    y = nc_data.variables['y'][:]\n",
    "    x = nc_data.variables['x'][:]\n",
    "    nt = len(t)\n",
    "    nrow = len(y)\n",
    "    ncol = len(x)\n",
    "    rd = np.zeros((nrow, ncol))  # create 0 array of the proper shape\n",
    "    for day in range(nt):\n",
    "        r_temp = nc_data.variables[str(nc_var)][day, :, :]\n",
    "        r_filled = np.ma.filled(r_temp, fill_value=0)    # fills in missing values with 0s (i think) \n",
    "        rd = rd+r_filled                                 # sequentially add each day's value in each cell to the empty frame  \n",
    "    r = rd/nt*365 # to create a one year average from all the years in model.  if want to add leap years add 0.25 \n",
    "    \n",
    "    # step 3: write each yearly average array to a .asc file\n",
    "    keyname = Desired_files[i] \n",
    "    writeArrayToArcGrid(r, os.path.join(outspace, \"{}_annual.asc\".format(keyname)), XLLCORNER, YLLCORNER, CELLSIZE, -999)\n",
    "    \n",
    "    # Step 4: calculate total amounts of water in cubic meters per day and create statistics dataframe\n",
    "    m3pd = ((cel_size**2)*r.sum()*.0254)/365 \n",
    "    print(\"{} total  {} [m3/d]\".format(keyname, '%.1f' % m3pd))\n",
    "    var.append(keyname) ; tot.append(m3pd)     # make lists to populate pandas dataframe\n",
    "    \n",
    "    nc_data.close()          # make sure to close the nc file so it doesnt stay open\n",
    "\n",
    "stat_frame = pd.DataFrame({'Variable' : var, 'total_[m3pd]': tot})    #in case you want the max and min#, \"Max_[in]\": mx, \"Min_[in]\":mn})\n",
    "stat_frame[\"total_[MGD]\"] = stat_frame[\"total_[m3pd]\"]/3785.41178       # put things in MGD if interested, 3785.41178 is number of gal in m3      \n",
    "Precip = list(stat_frame[stat_frame['Variable'] == 'rainfall']['total_[m3pd]'])[0]   # define the amount of calculated Precip\n",
    "Dir_net_inf = list(stat_frame[stat_frame['Variable'] == 'direct_net_infiltation']['total_[m3pd]'])[0]   # define the amount of calculated infiltration\n",
    "WB_ins = Precip + Dir_net_inf\n",
    "stat_frame['pct_of_pcip'] = stat_frame[\"total_[m3pd]\"]/WB_ins\n",
    "stat_frame.to_csv(os.path.join(outspace, \"stats_run7_{}m_cells.csv\".format(cel_size)))\n",
    "\n",
    "# how does the model balance? \n",
    "print(\"WATER BALANCE ratio: outs over ins water budget balanece =  {} % \".format(stat_frame['pct_of_pcip'].sum()-1))   # check water balance\n",
    "\n",
    "os.chdir(os.path.join(\"..\", 'run'))  # then back out to the home directory\n",
    "\n",
    "# calculate statistics for individual watersheds\n",
    "# note, for some reason will not overwrite csvs need to clear them out or recode to make this issue not an issue\n",
    "#create workspace\n",
    "outspace_table = os.path.join('..', 'output', 'post_prcessed_no_MFR', \"tables\")\n",
    "if not os.path.exists(outspace_table):\n",
    "    os.makedirs(outspace_table)\n",
    "sheds = (os.path.join(GIS_FOLDER, 'Watersheds\\\\Runoff_zones_sheds_WGS2S_clip.shp'))\n",
    "\n",
    "# process each raster layer into a table\n",
    "for i in (os.listdir(outspace)):\n",
    "    if i.endswith('.asc'):\n",
    "        outZSaT = ZonalStatisticsAsTable(sheds, \"SHED_NAME\", os.path.join(outspace, i), os.path.join(outspace_table, \"temptab.dbf\"))  # in arc format\n",
    "        arcpy.TableToTable_conversion(outZSaT, outspace_table, \"Table_{}_1.csv\".format(i))                                            # take table out of stupid arc format and put into csv format \n",
    "        \n",
    "# this block takes each of the csvs, reads them and calculates water volumnes (m3/d) for each watershed\n",
    "templist = []\n",
    "for c in (os.listdir(os.path.join(outspace, \"tables\"))):\n",
    "    if c.endswith('.csv'):\n",
    "        data = pd.read_csv(os.path.join(outspace, \"tables\", c))\n",
    "        keyname = c.split(\"Table_\")[1].split(\"_annual\")[0]                   # parameter being worked on\n",
    "        data[keyname] = (data['MEAN']*.0254/365) * data['AREA'] \n",
    "        temp_frame = data[[\"SHED_NAME\", keyname]]\n",
    "        templist.append(temp_frame)\n",
    "        \n",
    "summarry_frame1 = data[['SHED_NAME']]                                        # this is just sticking them all together into one dataframe\n",
    "for i in templist:\n",
    "    summarry_frame1 = summarry_frame1.merge(i, on ='SHED_NAME', how='outer')\n",
    "                          \n",
    "\n",
    "# that was in actual volumns, now to convert each component into a fraction of the rainfall...\n",
    "templist2 = []\n",
    "summarry_frame2 = data[['SHED_NAME']]\n",
    "for i in summarry_frame1.columns[1:]:\n",
    "    temp_frame = data[['SHED_NAME']] ; temp_frame[i.split(\"-\")[0]] = summarry_frame1[i]/summarry_frame1['rainfall']\n",
    "    templist2.append(temp_frame)\n",
    "    \n",
    "summarry_frame3 = data[['SHED_NAME']]\n",
    "for i in templist2:\n",
    "    summarry_frame3 = summarry_frame3.merge(i, on ='SHED_NAME', how='outer')\n",
    "                          \n",
    "summarry_frame_4000 = summarry_frame1.set_index('SHED_NAME')\n",
    "summarry_frame_4 = summarry_frame_4000.select_dtypes(exclude=['object'])*264.172/1000000   # convert to million gallons per day\n",
    "    \n",
    "summarry_frame3.to_csv(os.path.join(outspace, \"watershed_summary_stats_percentages.csv\"))\n",
    "summarry_frame1.to_csv(os.path.join(outspace, \"watershed_summary_stats_volume_m3pd.csv\"))\n",
    "summarry_frame_4.to_csv(os.path.join(outspace, \"watershed_summary_stats_volumes_MGD.csv\"))\n",
    "\n",
    "\n",
    "### MFR calculations      \n",
    "outspace = os.path.join('..', \"output\", 'post_prcessed_no_MFR')\n",
    "if not os.path.exists(outspace):\n",
    "    os.makedirs(outspace)\n",
    "\n",
    "# caclulate how much runoff to dump into the MFR area\n",
    "outspace_table = os.path.join('..', 'output', 'MFR_calcs', \"tables\")\n",
    "if not os.path.exists(outspace_table):\n",
    "    os.makedirs(outspace_table)\n",
    "    \n",
    "Contributing_area_leo = (os.path.join(GIS_FOLDER, 'MFR\\\\Contributing_MRF_Areas_leone.shp'))\n",
    "Contributing_area_taf = (os.path.join(GIS_FOLDER, 'MFR\\\\Contributing_MRF_Areas_tafuna.shp'))\n",
    "\n",
    "outZSaT_leo = ZonalStatisticsAsTable(Contributing_area_leo, \"SHED_NAME\", os.path.join(outspace, \"runoff_annual.asc\"), os.path.join(outspace_table, \"temptab_leo.dbf\"))  # in arc format\n",
    "arcpy.TableToTable_conversion(outZSaT_leo, outspace_table, \"runoff_MFR_leo.csv\")                                            # take table out of stupid arc format and put into csv format \n",
    "outZSaT_leo = ZonalStatisticsAsTable(Contributing_area_taf, \"SHED_NAME\", os.path.join(outspace, \"runoff_annual.asc\"), os.path.join(outspace_table, \"temptab_taf.dbf\"))  # in arc format\n",
    "arcpy.TableToTable_conversion(outZSaT_leo, outspace_table, \"runoff_MFR_taf.csv\") \n",
    "\n",
    "data_leo = pd.read_csv(os.path.join(outspace_table, \"runoff_MFR_leo.csv\"))\n",
    "data_taf = pd.read_csv(os.path.join(outspace_table, \"runoff_MFR_taf.csv\"))\n",
    "\n",
    "data_leo[\"AreaRunoff_m3pd\"] = (data_leo['MEAN']*.0254/365) * data_leo['AREA']    # this is how much runoff is in each MFR contributionzone\n",
    "data_taf[\"AreaRunoff_m3pd\"] = (data_taf['MEAN']*.0254/365) * data_taf['AREA']    # this is how much runoff is in each MFR contributionzone\n",
    "tot_MFR_leo = sum(data_leo['AreaRunoff_m3pd'])\n",
    "tot_MFR_taf = sum(data_taf['AreaRunoff_m3pd'])\n",
    "\n",
    "# calculate the MFR area and prepare input files\n",
    "workspace = os.path.join(input_folder,  'MFR')\n",
    "if not os.path.exists(workspace):\n",
    "    os.makedirs(workspace)\n",
    "\n",
    "arcpy.Project_management(os.path.join(GIS_FOLDER, 'MFR\\\\MFR_infiltration_area_leone.shp'),  os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), sr_project) \n",
    "arcpy.AddField_management(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), \"MFR_inch\", \"DOUBLE\")    # add Active cell unit field\n",
    "arcpy.AddGeometryAttributes_management(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), \"AREA\")\n",
    "Total_MFR_area_leo = 0                                                                                                        # stupid block just to calculate the total area\n",
    "with arcpy.da.SearchCursor(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), \"POLY_AREA\") as cursor:\n",
    "    for row in cursor:\n",
    "        Total_MFR_area_leo = Total_MFR_area_leo + row[0]\n",
    "\n",
    "arcpy.Project_management(os.path.join(GIS_FOLDER, 'MFR\\\\MFR_infiltration_area_tafuna.shp'),  os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), sr_project) \n",
    "arcpy.AddField_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), \"MFR_inch\", \"DOUBLE\")    # add Active cell unit field\n",
    "arcpy.AddGeometryAttributes_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), \"AREA\")\n",
    "Total_MFR_area_taf = 0                                                                                                        # stupid block just to calculate the total area\n",
    "with arcpy.da.SearchCursor(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), \"POLY_AREA\") as cursor:\n",
    "    for row in cursor:\n",
    "        Total_MFR_area_taf = Total_MFR_area_taf + row[0]\n",
    "        \n",
    "Inches_of_MFR_across_leo = (tot_MFR_leo/Total_MFR_area_leo/0.0254) * 0.75   # note this 75% number if directly from Izuka 2007\n",
    "Inches_of_MFR_across_taf = (tot_MFR_taf/Total_MFR_area_taf/0.0254) * 0.75   # note this 75% number if directly from Izuka 2007\n",
    "\n",
    "arcpy.CalculateField_management(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), \"MFR_inch\", \"!MFR_inch! + {}\".format(Inches_of_MFR_across_leo), \"PYTHON3\") # calculate the appropriate amount of infitration in inches spread over all MFR zone\n",
    "arcpy.CalculateField_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), \"MFR_inch\", \"!MFR_inch! + {}\".format(Inches_of_MFR_across_taf), \"PYTHON3\") # calculate the appropriate amount of infitration in inches spread over all MFR zone\n",
    "\n",
    "arcpy.Erase_analysis(Grid_shp, os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'),  os.path.join(workspace, 'MFR_infiltration_area_leone_bound.shp'))\n",
    "arcpy.Erase_analysis(Grid_shp, os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'),  os.path.join(workspace, 'MFR_infiltration_area_tafuna_bound.shp'))\n",
    "\n",
    "arcpy.Merge_management([os.path.join(workspace, 'MFR_infiltration_area_leone_bound.shp'), os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp')], os.path.join(workspace, 'MFR_infiltration_area_leone_ready.shp'))\n",
    "arcpy.Merge_management([os.path.join(workspace, 'MFR_infiltration_area_tafuna_bound.shp'), os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp')], os.path.join(workspace, 'MFR_infiltration_area_tafuna_ready.shp'))\n",
    "\n",
    "arcpy.PolygonToRaster_conversion(os.path.join(workspace, 'MFR_infiltration_area_leone_ready.shp'), \"MFR_inch\", os.path.join(workspace, \"MFR_Rast_L\"), cell_assignment=\"MAXIMUM_AREA\",  cellsize=cel_size)\n",
    "arcpy.PolygonToRaster_conversion(os.path.join(workspace, 'MFR_infiltration_area_tafuna_ready.shp'), \"MFR_inch\", os.path.join(workspace, \"MFR_Rast_T\"), cell_assignment=\"MAXIMUM_AREA\",  cellsize=cel_size)\n",
    "\n",
    "arcpy.RasterToASCII_conversion(os.path.join(workspace, \"MFR_Rast_L\"), os.path.join(workspace, \"MFR_Rast_L.asc\"))\n",
    "arcpy.RasterToASCII_conversion(os.path.join(workspace, \"MFR_Rast_T\"), os.path.join(workspace, \"MFR_Rast_T.asc\"))\n",
    "\n",
    "arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'))\n",
    "arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'))\n",
    "arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_leone_bound.shp'))\n",
    "arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_bound.shp'))\n",
    "arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_leone_ready.shp'))\n",
    "arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_ready.shp'))\n",
    "arcpy.Delete_management(os.path.join(workspace, 'MFR_Rast_L'))\n",
    "arcpy.Delete_management(os.path.join(workspace, 'MFR_Rast_T'))\n",
    "\n",
    "# now combine the MFR raster into the other direct infiltration rasters\n",
    "arcpy.Plus_3d(os.path.join(input_folder,  'MFR', \"MFR_Rast_L.asc\"), os.path.join(input_folder,  'Direct_infiltration', \"WLOSDrast\"), os.path.join(input_folder,  'Direct_infiltration', \"temprast2\"))\n",
    "arcpy.Plus_3d(os.path.join(input_folder,  'MFR', \"MFR_Rast_T.asc\"), os.path.join(input_folder,  'Direct_infiltration', \"temprast2\"), os.path.join(input_folder,  'Direct_infiltration', \"temprast3\"))\n",
    "arcpy.RasterToASCII_conversion(os.path.join(input_folder,  'Direct_infiltration', \"temprast3\"), os.path.join(input_folder,  'Direct_infiltration', \"Total_inlf_in.asc\"))\n",
    "\n",
    "print('MFR leo in MGD is {}'.format(tot_MFR_leo*264.172/1000000))\n",
    "print('MFR taf in MGD is {}'.format(tot_MFR_taf*264.172/1000000))\n",
    "print('MFR total in MGD is {}'.format((tot_MFR_leo+tot_MFR_taf)*264.172/1000000))\n",
    "\n",
    "# Run da Model again, this time including the MFR\n",
    "# Executable and control file copies\n",
    "shutil.copy2(os.path.join(\".\" , 'swb2.exe') ,os.path.join('..', 'output')) \n",
    "shutil.copy2(os.path.join(\".\" , Control_File_Name) ,os.path.join('..', 'output')) \n",
    "\n",
    "os.chdir(os.path.join(\"..\", \"output\"))\n",
    "subprocess.call('swb2.exe {}'.format(Control_File_Name), shell=True)\n",
    "os.chdir(os.path.join(\"..\", \"run\"))\n",
    "\n",
    "# Post process the files again, this time with the MFR added \n",
    "outspace = os.path.join('..', \"output\", 'post_prcessed_with_MFR')\n",
    "if not os.path.exists(outspace):\n",
    "    os.makedirs(outspace)\n",
    "\n",
    "# post process the whole model domain\n",
    "os.chdir(os.path.join(\"..\", 'output'))  # difficulty in making the path to the file so need to change into the output directory\n",
    "var = []; tot = []; nclist = []\n",
    "\n",
    "# Step 1: make list of files that you wish to process \n",
    "for i in Desired_files:\n",
    "    Da_file = create_file_reference(i)\n",
    "    nclist.append(Da_file)\n",
    "    \n",
    "# Step 2 average the daily dimension (len(t) is # of days in the run) to annual \n",
    "for i, f in enumerate(nclist):\n",
    "    nc_data = nc.Dataset(nclist[i])\n",
    "    nc_attrs, nc_dims, nc_vars = ncdump(nc_data)\n",
    "    nc_var = nc_vars[3]\n",
    "    t = nc_data.variables['time'][:]\n",
    "    y = nc_data.variables['y'][:]\n",
    "    x = nc_data.variables['x'][:]\n",
    "    nt = len(t)\n",
    "    nrow = len(y)\n",
    "    ncol = len(x)\n",
    "    rd = np.zeros((nrow, ncol))  # create 0 array of the proper shape\n",
    "    for day in range(nt):\n",
    "        r_temp = nc_data.variables[str(nc_var)][day, :, :]\n",
    "        r_filled = np.ma.filled(r_temp, fill_value=0)    # fills in missing values with 0s (i think) \n",
    "        rd = rd+r_filled                                 # sequentially add each day's value in each cell to the empty frame  \n",
    "    r = rd/nt*365 # to create a one year average from all the years in model.  if want to add leap years add 0.25 \n",
    "    \n",
    "    # step 3: write each yearly average array to a .asc file\n",
    "    keyname = Desired_files[i] \n",
    "    writeArrayToArcGrid(r, os.path.join(outspace, \"{}_annual.asc\".format(keyname)), XLLCORNER, YLLCORNER, CELLSIZE, -999)\n",
    "    \n",
    "    # Step 4: calculate total amounts of water in cubic meters per day and create statistics dataframe\n",
    "    m3pd = ((cel_size**2)*r.sum()*.0254)/365 \n",
    "    print(\"{} total  {} [m3/d]\".format(keyname, '%.1f' % m3pd))\n",
    "    var.append(keyname) ; tot.append(m3pd)     # make lists to populate pandas dataframe\n",
    "    \n",
    "    nc_data.close()          # make sure to close the nc file so it doesnt stay open\n",
    "\n",
    "stat_frame = pd.DataFrame({'Variable' : var, 'total_[m3pd]': tot})    #in case you want the max and min#, \"Max_[in]\": mx, \"Min_[in]\":mn})\n",
    "stat_frame[\"total_[MGD]\"] = stat_frame[\"total_[m3pd]\"]/3785.41178       # put things in MGD if interested, 3785.41178 is number of gal in m3      \n",
    "Precip = list(stat_frame[stat_frame['Variable'] == 'rainfall']['total_[m3pd]'])[0]   # define the amount of calculated Precip\n",
    "Dir_net_inf = list(stat_frame[stat_frame['Variable'] == 'direct_net_infiltation']['total_[m3pd]'])[0]   # define the amount of calculated infiltration\n",
    "WB_ins = Precip + Dir_net_inf\n",
    "stat_frame['pct_of_pcip'] = stat_frame[\"total_[m3pd]\"]/WB_ins\n",
    "stat_frame.to_csv(os.path.join(outspace, \"stats_run7_{}m_cells.csv\".format(cel_size)))\n",
    "\n",
    "# how does the model balance? \n",
    "print(\"WATER BALANCE ratio: outs over ins water budget balanece =  {} % \".format(stat_frame['pct_of_pcip'].sum()-1))   # check water balance\n",
    "\n",
    "os.chdir(os.path.join(\"..\", 'run'))  # then back out to the home directory\n",
    "\n",
    "# calculate statistics for individual watersheds\n",
    "# note, for some reason will not overwrite csvs need to clear them out or recode to make this issue not an issue\n",
    "#create workspace\n",
    "outspace_table = os.path.join('..', 'output', 'post_prcessed_with_MFR', \"tables\")\n",
    "if not os.path.exists(outspace_table):\n",
    "    os.makedirs(outspace_table)\n",
    "sheds = (os.path.join(GIS_FOLDER, 'Watersheds\\\\Runoff_zones_sheds_WGS2S_clip.shp'))\n",
    "\n",
    "# process each raster layer into a table\n",
    "for i in (os.listdir(outspace)):\n",
    "    if i.endswith('.asc'):\n",
    "        outZSaT = ZonalStatisticsAsTable(sheds, \"SHED_NAME\", os.path.join(outspace, i), os.path.join(outspace_table, \"temptab.dbf\"))  # in arc format\n",
    "        arcpy.TableToTable_conversion(outZSaT, outspace_table, \"Table_{}_1.csv\".format(i))                                            # take table out of stupid arc format and put into csv format \n",
    "        \n",
    "# this block takes each of the csvs, reads them and calculates water volumnes (m3/d) for each watershed\n",
    "templist = []\n",
    "for c in (os.listdir(os.path.join(outspace, \"tables\"))):\n",
    "    if c.endswith('.csv'):\n",
    "        data = pd.read_csv(os.path.join(outspace, \"tables\", c))\n",
    "        keyname = c.split(\"Table_\")[1].split(\"_annual\")[0]                   # parameter being worked on\n",
    "        data[keyname] = (data['MEAN']*.0254/365) * data['AREA'] \n",
    "        temp_frame = data[[\"SHED_NAME\", keyname]]\n",
    "        templist.append(temp_frame)\n",
    "        \n",
    "summarry_frame1 = data[['SHED_NAME']]                                        # this is just sticking them all together into one dataframe\n",
    "for i in templist:\n",
    "    summarry_frame1 = summarry_frame1.merge(i, on ='SHED_NAME', how='outer')\n",
    "                          \n",
    "\n",
    "# that was in actual volumns, now to convert each component into a fraction of the rainfall...\n",
    "templist2 = []\n",
    "summarry_frame2 = data[['SHED_NAME']]\n",
    "for i in summarry_frame1.columns[1:]:\n",
    "    temp_frame = data[['SHED_NAME']] ; temp_frame[i.split(\"-\")[0]] = summarry_frame1[i]/summarry_frame1['rainfall']\n",
    "    templist2.append(temp_frame)\n",
    "    \n",
    "summarry_frame3 = data[['SHED_NAME']]\n",
    "for i in templist2:\n",
    "    summarry_frame3 = summarry_frame3.merge(i, on ='SHED_NAME', how='outer')\n",
    "                          \n",
    "summarry_frame_4000 = summarry_frame1.set_index('SHED_NAME')\n",
    "summarry_frame_4 = summarry_frame_4000.select_dtypes(exclude=['object'])*264.172/1000000   # convert to million gallons per day\n",
    "    \n",
    "summarry_frame3.to_csv(os.path.join(outspace, \"watershed_summary_stats_percentages.csv\"))\n",
    "summarry_frame1.to_csv(os.path.join(outspace, \"watershed_summary_stats_volume_m3pd.csv\"))\n",
    "summarry_frame_4.to_csv(os.path.join(outspace, \"watershed_summary_stats_volumes_MGD.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_model(name):\n",
    "    print(name)\n",
    "\n",
    "    #### import modules\n",
    "    import numpy as np\n",
    "    import arcpy\n",
    "    import os\n",
    "    import sys\n",
    "   # from arcpy.sa import *\n",
    "    import pandas as pd\n",
    "    #import gdal\n",
    "    from arcpy import env\n",
    "    import shutil\n",
    "    import numpy.ma as ma\n",
    "    import netCDF4 as nc\n",
    "    import subprocess\n",
    "    import re\n",
    "    # this is a list of additional functions to load up, as to not clutter the script\n",
    "   # %run ../../Std_input/COMMON/plot_and_table_functions\n",
    "\n",
    "    # set properties\n",
    "    arcpy.env.overwriteOutput = True # make sure overwrite files is on\n",
    "    # projection definition \n",
    "    sr_project = arcpy.SpatialReference(32702)   # Project dataset into WGS84\n",
    "    cel_size = 100     # in m \n",
    "    Control_File_Name = 'Tutuila_cal_controlFile.ctl'\n",
    "\n",
    "\n",
    "    #### General coverages and paths. More, basic model setup.\n",
    "    GIS_FOLDER = os.path.join('..', '..', 'Raw_GIS_Data')\n",
    "    STD_INPUT_FOLDER = os.path.join('..', '..', 'Std_input')\n",
    "    # path to the grid bound\n",
    "    Grid_shp = os.path.join(GIS_FOLDER, 'grid_bound.shp')\n",
    "\n",
    "    if not os.path.exists(os.path.join('..', 'output//')):\n",
    "        os.makedirs(os.path.join('..', 'output//'))\n",
    "\n",
    "\n",
    "    input_folder = os.path.join(\"..\", \"..\", \"Model_workspace\", \"input\") \n",
    "\n",
    "    # Move in other standard input files and modify control file to the shape of the current run\n",
    "    # modify the control file grid for the given run   (note this uses dimensions from the rainfall adjustment grid in april)\n",
    "    with open(os.path.join(input_folder, 'RF_adj_grids', 'rfadj_apr.asc'), 'r') as dims_file:   # open an ASC file and get the dimenstions out of it \n",
    "        dimsfile1 = dims_file.read().splitlines(True)\n",
    "        x_dim = float(re.findall('\\d+', dimsfile1[0])[-1])    \n",
    "        y_dim = float(re.findall('\\d+', dimsfile1[1])[-1])\n",
    "\n",
    "    with open(os.path.join('.', Control_File_Name), 'r') as fin:   # open file \n",
    "        data = fin.read().splitlines(True)\n",
    "    with open(os.path.join('.', Control_File_Name), 'w') as fout:     # delete first line\n",
    "        fout.writelines(data[1:])\n",
    "    new_first = 'GRID {} {} 515000. 8409000. {} '.format(x_dim, y_dim, cel_size)  # new first line \n",
    "    with open(os.path.join('.', Control_File_Name), 'r+') as file:                # add in new first line and save file  \n",
    "        file_data = file.read()\n",
    "        file. seek(0, 0)\n",
    "        file. write(new_first + '\\n' + file_data)\n",
    "\n",
    "    # land use lookup file\n",
    "    shutil.copy2(os.path.join(STD_INPUT_FOLDER, 'Landuse_lookup_maui_mod5.txt') ,os.path.join(input_folder))    \n",
    "\n",
    "    # Simple RO : RF ratios file\n",
    "    shutil.copy2(os.path.join(GIS_FOLDER, 'Runofftorainfall2\\\\RO_Rf_ratios_real_monthly3_2000_2010.txt') ,os.path.join(input_folder)) # note this is from the simplified version with zone IDs starting at 1\n",
    "\n",
    "    # Rain Fragments file\n",
    "    shutil.copy2(os.path.join(STD_INPUT_FOLDER, \"Fragments\", 'Rainfall_fragments_2001.prn') ,os.path.join(input_folder))  \n",
    "\n",
    "    #  Fragments sequence file\n",
    "    shutil.copy2(os.path.join(STD_INPUT_FOLDER, \"Fragments\", 'Sequence_file_2002.prn') ,os.path.join(input_folder)) \n",
    "\n",
    "    # need to run this before the 1st model run to re-fresh the direct net infiltration coverage to not include the MFR. \n",
    "    arcpy.Plus_3d(os.path.join(input_folder,  'Direct_infiltration',  \"A_WL_Rast.asc\"), os.path.join(input_folder,  'Direct_infiltration', \"OSDS_inlf_in.asc\"), os.path.join(input_folder,  'Direct_infiltration', \"temprast\"))\n",
    "    arcpy.RasterToASCII_conversion(os.path.join(input_folder,  'Direct_infiltration', \"temprast\"), os.path.join(input_folder,  'Direct_infiltration', \"Total_inlf_in.asc\"))\n",
    "\n",
    "\n",
    "    # RUN Da MODEL (with no MFR) \n",
    "    os.chdir(os.path.join(\"..\", \"run\"))\n",
    "    # Executable and control file copies\n",
    "    shutil.copy2(os.path.join(\".\" , 'swb2.exe') ,os.path.join('..', 'output')) \n",
    "    shutil.copy2(os.path.join(\".\" , Control_File_Name) ,os.path.join('..', 'output')) \n",
    "\n",
    "    os.chdir(os.path.join(\"..\", \"output\"))\n",
    "    subprocess.call('swb2.exe {}'.format(Control_File_Name), shell=True)\n",
    "    os.chdir(os.path.join(\"..\", \"run\"))\n",
    "\n",
    "    ### Post process da files\n",
    "    outspace = os.path.join('..', \"output\", 'post_prcessed_no_MFR')\n",
    "    if not os.path.exists(outspace):\n",
    "        os.makedirs(outspace)\n",
    "\n",
    "    # Parameters\n",
    "    Desired_files = ['actual_et',  'direct_net_infiltation', 'direct_soil_moisture',\n",
    "                 'interception', 'net_infiltration', 'rainfall', 'runoff'] # 'delta_soil_storage',  'irrigation', \n",
    "    XLLCORNER =      515000.000\n",
    "    YLLCORNER =      8409000.000\n",
    "    CELLSIZE  =      cel_size\n",
    "\n",
    "    # functions\n",
    "    def create_file_reference( component_name ):\n",
    "        '''\n",
    "        This is a simple convenience function that will form a path and filename to a\n",
    "        given water budget component\n",
    "        '''\n",
    "        # specify the prefix, path to SWB2 output, timeframe, and resolution\n",
    "        #output_path = os.path.join(os.getcwd(), \"output\")\n",
    "        #prefix      = '\\\\'\n",
    "        start_year  = '2000-01-01'\n",
    "        end_year    = '2009-12-31'\n",
    "        ncol        = str(int(x_dim))\n",
    "        nrow        = str(int(y_dim))\n",
    "        return(  component_name + '__' + start_year + '_' \n",
    "              + end_year + '__' + nrow + '_by_' + ncol + '.nc' )\n",
    "\n",
    "    # some other functions to post process stuff\n",
    "\n",
    "    def ncdump(nc_fid):\n",
    "        '''ncdump outputs dimensions, variables and their attribute information of netCDF4 files'''\n",
    "        nc_attrs = nc_fid.ncattrs()\n",
    "        nc_dims = [dim for dim in nc_fid.dimensions]  \n",
    "        nc_vars = [var for var in nc_fid.variables] \n",
    "        return nc_attrs, nc_dims, nc_vars\n",
    "\n",
    "    def writeArrayToArcGrid(arr,filename,xll,yll,cellsize,no_data_val):\n",
    "        \"\"\" this takes a 2d numpy array and turns it into an .asc file \"\"\"\n",
    "        arr                = np.copy(arr)\n",
    "        arr[np.isnan(arr)] = no_data_val\n",
    "        headerstring       = bytes('NCOLS %d\\nNROWS %d\\nXLLCENTER %f\\nYLLCENTER %f\\nCELLSIZE %f\\nNODATA_value %f\\n' % \n",
    "            (arr.shape[1], arr.shape[0], xll, yll, cellsize, no_data_val), 'UTF-8')\n",
    "\n",
    "        with open(filename,'wb') as fout:\n",
    "            fout.write(headerstring)\n",
    "            np.savetxt(fout,arr,'%5.2f')\n",
    "\n",
    "\n",
    "    # post process the whole model domain\n",
    "    os.chdir(os.path.join(\"..\", 'output'))  # difficulty in making the path to the file so need to change into the output directory\n",
    "    var = []; tot = []; nclist = []\n",
    "\n",
    "    # Step 1: make list of files that you wish to process \n",
    "    for i in Desired_files:\n",
    "        Da_file = create_file_reference(i)\n",
    "        nclist.append(Da_file)\n",
    "\n",
    "    # Step 2 average the daily dimension (len(t) is # of days in the run) to annual \n",
    "    for i, f in enumerate(nclist):\n",
    "        nc_data = nc.Dataset(nclist[i])\n",
    "        nc_attrs, nc_dims, nc_vars = ncdump(nc_data)\n",
    "        nc_var = nc_vars[3]\n",
    "        t = nc_data.variables['time'][:]\n",
    "        y = nc_data.variables['y'][:]\n",
    "        x = nc_data.variables['x'][:]\n",
    "        nt = len(t)\n",
    "        nrow = len(y)\n",
    "        ncol = len(x)\n",
    "        rd = np.zeros((nrow, ncol))  # create 0 array of the proper shape\n",
    "        for day in range(nt):\n",
    "            r_temp = nc_data.variables[str(nc_var)][day, :, :]\n",
    "            r_filled = np.ma.filled(r_temp, fill_value=0)    # fills in missing values with 0s (i think) \n",
    "            rd = rd+r_filled                                 # sequentially add each day's value in each cell to the empty frame  \n",
    "        r = rd/nt*365 # to create a one year average from all the years in model.  if want to add leap years add 0.25 \n",
    "\n",
    "        # step 3: write each yearly average array to a .asc file\n",
    "        keyname = Desired_files[i] \n",
    "        writeArrayToArcGrid(r, os.path.join(outspace, \"{}_annual.asc\".format(keyname)), XLLCORNER, YLLCORNER, CELLSIZE, -999)\n",
    "\n",
    "        # Step 4: calculate total amounts of water in cubic meters per day and create statistics dataframe\n",
    "        m3pd = ((cel_size**2)*r.sum()*.0254)/365 \n",
    "        print(\"{} total  {} [m3/d]\".format(keyname, '%.1f' % m3pd))\n",
    "        var.append(keyname) ; tot.append(m3pd)     # make lists to populate pandas dataframe\n",
    "\n",
    "        nc_data.close()          # make sure to close the nc file so it doesnt stay open\n",
    "\n",
    "    stat_frame = pd.DataFrame({'Variable' : var, 'total_[m3pd]': tot})    #in case you want the max and min#, \"Max_[in]\": mx, \"Min_[in]\":mn})\n",
    "    stat_frame[\"total_[MGD]\"] = stat_frame[\"total_[m3pd]\"]/3785.41178       # put things in MGD if interested, 3785.41178 is number of gal in m3      \n",
    "    Precip = list(stat_frame[stat_frame['Variable'] == 'rainfall']['total_[m3pd]'])[0]   # define the amount of calculated Precip\n",
    "    Dir_net_inf = list(stat_frame[stat_frame['Variable'] == 'direct_net_infiltation']['total_[m3pd]'])[0]   # define the amount of calculated infiltration\n",
    "    WB_ins = Precip + Dir_net_inf\n",
    "    stat_frame['pct_of_pcip'] = stat_frame[\"total_[m3pd]\"]/WB_ins\n",
    "    stat_frame.to_csv(os.path.join(outspace, \"stats_run7_{}m_cells.csv\".format(cel_size)))\n",
    "\n",
    "    # how does the model balance? \n",
    "    print(\"WATER BALANCE ratio: outs over ins water budget balanece =  {} % \".format(stat_frame['pct_of_pcip'].sum()-1))   # check water balance\n",
    "\n",
    "    os.chdir(os.path.join(\"..\", 'run'))  # then back out to the home directory\n",
    "\n",
    "    # calculate statistics for individual watersheds\n",
    "    # note, for some reason will not overwrite csvs need to clear them out or recode to make this issue not an issue\n",
    "    #create workspace\n",
    "    outspace_table = os.path.join('..', 'output', 'post_prcessed_no_MFR', \"tables\")\n",
    "    if not os.path.exists(outspace_table):\n",
    "        os.makedirs(outspace_table)\n",
    "    sheds = (os.path.join(GIS_FOLDER, 'Watersheds\\\\Runoff_zones_sheds_WGS2S_clip.shp'))\n",
    "\n",
    "    # process each raster layer into a table\n",
    "    for i in (os.listdir(outspace)):\n",
    "        if i.endswith('.asc'):\n",
    "            outZSaT = ZonalStatisticsAsTable(sheds, \"SHED_NAME\", os.path.join(outspace, i), os.path.join(outspace_table, \"temptab.dbf\"))  # in arc format\n",
    "            arcpy.TableToTable_conversion(outZSaT, outspace_table, \"Table_{}_1.csv\".format(i))                                            # take table out of stupid arc format and put into csv format \n",
    "\n",
    "    # this block takes each of the csvs, reads them and calculates water volumnes (m3/d) for each watershed\n",
    "    templist = []\n",
    "    for c in (os.listdir(os.path.join(outspace, \"tables\"))):\n",
    "        if c.endswith('.csv'):\n",
    "            data = pd.read_csv(os.path.join(outspace, \"tables\", c))\n",
    "            keyname = c.split(\"Table_\")[1].split(\"_annual\")[0]                   # parameter being worked on\n",
    "            data[keyname] = (data['MEAN']*.0254/365) * data['AREA'] \n",
    "            temp_frame = data[[\"SHED_NAME\", keyname]]\n",
    "            templist.append(temp_frame)\n",
    "\n",
    "    summarry_frame1 = data[['SHED_NAME']]                                        # this is just sticking them all together into one dataframe\n",
    "    for i in templist:\n",
    "        summarry_frame1 = summarry_frame1.merge(i, on ='SHED_NAME', how='outer')\n",
    "\n",
    "\n",
    "    # that was in actual volumns, now to convert each component into a fraction of the rainfall...\n",
    "    templist2 = []\n",
    "    summarry_frame2 = data[['SHED_NAME']]\n",
    "    for i in summarry_frame1.columns[1:]:\n",
    "        temp_frame = data[['SHED_NAME']] ; temp_frame[i.split(\"-\")[0]] = summarry_frame1[i]/summarry_frame1['rainfall']\n",
    "        templist2.append(temp_frame)\n",
    "\n",
    "    summarry_frame3 = data[['SHED_NAME']]\n",
    "    for i in templist2:\n",
    "        summarry_frame3 = summarry_frame3.merge(i, on ='SHED_NAME', how='outer')\n",
    "\n",
    "    summarry_frame_4000 = summarry_frame1.set_index('SHED_NAME')\n",
    "    summarry_frame_4 = summarry_frame_4000.select_dtypes(exclude=['object'])*264.172/1000000   # convert to million gallons per day\n",
    "\n",
    "    summarry_frame3.to_csv(os.path.join(outspace, \"watershed_summary_stats_percentages.csv\"))\n",
    "    summarry_frame1.to_csv(os.path.join(outspace, \"watershed_summary_stats_volume_m3pd.csv\"))\n",
    "    summarry_frame_4.to_csv(os.path.join(outspace, \"watershed_summary_stats_volumes_MGD.csv\"))\n",
    "\n",
    "\n",
    "    ### MFR calculations      \n",
    "    outspace = os.path.join('..', \"output\", 'post_prcessed_no_MFR')\n",
    "    if not os.path.exists(outspace):\n",
    "        os.makedirs(outspace)\n",
    "\n",
    "    # caclulate how much runoff to dump into the MFR area\n",
    "    outspace_table = os.path.join('..', 'output', 'MFR_calcs', \"tables\")\n",
    "    if not os.path.exists(outspace_table):\n",
    "        os.makedirs(outspace_table)\n",
    "\n",
    "    Contributing_area_leo = (os.path.join(GIS_FOLDER, 'MFR\\\\Contributing_MRF_Areas_leone.shp'))\n",
    "    Contributing_area_taf = (os.path.join(GIS_FOLDER, 'MFR\\\\Contributing_MRF_Areas_tafuna.shp'))\n",
    "\n",
    "    outZSaT_leo = ZonalStatisticsAsTable(Contributing_area_leo, \"SHED_NAME\", os.path.join(outspace, \"runoff_annual.asc\"), os.path.join(outspace_table, \"temptab_leo.dbf\"))  # in arc format\n",
    "    arcpy.TableToTable_conversion(outZSaT_leo, outspace_table, \"runoff_MFR_leo.csv\")                                            # take table out of stupid arc format and put into csv format \n",
    "    outZSaT_leo = ZonalStatisticsAsTable(Contributing_area_taf, \"SHED_NAME\", os.path.join(outspace, \"runoff_annual.asc\"), os.path.join(outspace_table, \"temptab_taf.dbf\"))  # in arc format\n",
    "    arcpy.TableToTable_conversion(outZSaT_leo, outspace_table, \"runoff_MFR_taf.csv\") \n",
    "\n",
    "    data_leo = pd.read_csv(os.path.join(outspace_table, \"runoff_MFR_leo.csv\"))\n",
    "    data_taf = pd.read_csv(os.path.join(outspace_table, \"runoff_MFR_taf.csv\"))\n",
    "\n",
    "    data_leo[\"AreaRunoff_m3pd\"] = (data_leo['MEAN']*.0254/365) * data_leo['AREA']    # this is how much runoff is in each MFR contributionzone\n",
    "    data_taf[\"AreaRunoff_m3pd\"] = (data_taf['MEAN']*.0254/365) * data_taf['AREA']    # this is how much runoff is in each MFR contributionzone\n",
    "    tot_MFR_leo = sum(data_leo['AreaRunoff_m3pd'])\n",
    "    tot_MFR_taf = sum(data_taf['AreaRunoff_m3pd'])\n",
    "\n",
    "    # calculate the MFR area and prepare input files\n",
    "    workspace = os.path.join(input_folder,  'MFR')\n",
    "    if not os.path.exists(workspace):\n",
    "        os.makedirs(workspace)\n",
    "\n",
    "    arcpy.Project_management(os.path.join(GIS_FOLDER, 'MFR\\\\MFR_infiltration_area_leone.shp'),  os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), sr_project) \n",
    "    arcpy.AddField_management(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), \"MFR_inch\", \"DOUBLE\")    # add Active cell unit field\n",
    "    arcpy.AddGeometryAttributes_management(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), \"AREA\")\n",
    "    Total_MFR_area_leo = 0                                                                                                        # stupid block just to calculate the total area\n",
    "    with arcpy.da.SearchCursor(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), \"POLY_AREA\") as cursor:\n",
    "        for row in cursor:\n",
    "            Total_MFR_area_leo = Total_MFR_area_leo + row[0]\n",
    "\n",
    "    arcpy.Project_management(os.path.join(GIS_FOLDER, 'MFR\\\\MFR_infiltration_area_tafuna.shp'),  os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), sr_project) \n",
    "    arcpy.AddField_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), \"MFR_inch\", \"DOUBLE\")    # add Active cell unit field\n",
    "    arcpy.AddGeometryAttributes_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), \"AREA\")\n",
    "    Total_MFR_area_taf = 0                                                                                                        # stupid block just to calculate the total area\n",
    "    with arcpy.da.SearchCursor(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), \"POLY_AREA\") as cursor:\n",
    "        for row in cursor:\n",
    "            Total_MFR_area_taf = Total_MFR_area_taf + row[0]\n",
    "\n",
    "    Inches_of_MFR_across_leo = (tot_MFR_leo/Total_MFR_area_leo/0.0254) * 0.75   # note this 75% number if directly from Izuka 2007\n",
    "    Inches_of_MFR_across_taf = (tot_MFR_taf/Total_MFR_area_taf/0.0254) * 0.75   # note this 75% number if directly from Izuka 2007\n",
    "\n",
    "    arcpy.CalculateField_management(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'), \"MFR_inch\", \"!MFR_inch! + {}\".format(Inches_of_MFR_across_leo), \"PYTHON3\") # calculate the appropriate amount of infitration in inches spread over all MFR zone\n",
    "    arcpy.CalculateField_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'), \"MFR_inch\", \"!MFR_inch! + {}\".format(Inches_of_MFR_across_taf), \"PYTHON3\") # calculate the appropriate amount of infitration in inches spread over all MFR zone\n",
    "\n",
    "    arcpy.Erase_analysis(Grid_shp, os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'),  os.path.join(workspace, 'MFR_infiltration_area_leone_bound.shp'))\n",
    "    arcpy.Erase_analysis(Grid_shp, os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'),  os.path.join(workspace, 'MFR_infiltration_area_tafuna_bound.shp'))\n",
    "\n",
    "    arcpy.Merge_management([os.path.join(workspace, 'MFR_infiltration_area_leone_bound.shp'), os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp')], os.path.join(workspace, 'MFR_infiltration_area_leone_ready.shp'))\n",
    "    arcpy.Merge_management([os.path.join(workspace, 'MFR_infiltration_area_tafuna_bound.shp'), os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp')], os.path.join(workspace, 'MFR_infiltration_area_tafuna_ready.shp'))\n",
    "\n",
    "    arcpy.PolygonToRaster_conversion(os.path.join(workspace, 'MFR_infiltration_area_leone_ready.shp'), \"MFR_inch\", os.path.join(workspace, \"MFR_Rast_L\"), cell_assignment=\"MAXIMUM_AREA\",  cellsize=cel_size)\n",
    "    arcpy.PolygonToRaster_conversion(os.path.join(workspace, 'MFR_infiltration_area_tafuna_ready.shp'), \"MFR_inch\", os.path.join(workspace, \"MFR_Rast_T\"), cell_assignment=\"MAXIMUM_AREA\",  cellsize=cel_size)\n",
    "\n",
    "    arcpy.RasterToASCII_conversion(os.path.join(workspace, \"MFR_Rast_L\"), os.path.join(workspace, \"MFR_Rast_L.asc\"))\n",
    "    arcpy.RasterToASCII_conversion(os.path.join(workspace, \"MFR_Rast_T\"), os.path.join(workspace, \"MFR_Rast_T.asc\"))\n",
    "\n",
    "    arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_leone_projected.shp'))\n",
    "    arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_projected.shp'))\n",
    "    arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_leone_bound.shp'))\n",
    "    arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_bound.shp'))\n",
    "    arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_leone_ready.shp'))\n",
    "    arcpy.Delete_management(os.path.join(workspace, 'MFR_infiltration_area_tafuna_ready.shp'))\n",
    "    arcpy.Delete_management(os.path.join(workspace, 'MFR_Rast_L'))\n",
    "    arcpy.Delete_management(os.path.join(workspace, 'MFR_Rast_T'))\n",
    "\n",
    "    # now combine the MFR raster into the other direct infiltration rasters\n",
    "    arcpy.Plus_3d(os.path.join(input_folder,  'MFR', \"MFR_Rast_L.asc\"), os.path.join(input_folder,  'Direct_infiltration', \"WLOSDrast\"), os.path.join(input_folder,  'Direct_infiltration', \"temprast2\"))\n",
    "    arcpy.Plus_3d(os.path.join(input_folder,  'MFR', \"MFR_Rast_T.asc\"), os.path.join(input_folder,  'Direct_infiltration', \"temprast2\"), os.path.join(input_folder,  'Direct_infiltration', \"temprast3\"))\n",
    "    arcpy.RasterToASCII_conversion(os.path.join(input_folder,  'Direct_infiltration', \"temprast3\"), os.path.join(input_folder,  'Direct_infiltration', \"Total_inlf_in.asc\"))\n",
    "\n",
    "    print('MFR leo in MGD is {}'.format(tot_MFR_leo*264.172/1000000))\n",
    "    print('MFR taf in MGD is {}'.format(tot_MFR_taf*264.172/1000000))\n",
    "    print('MFR total in MGD is {}'.format((tot_MFR_leo+tot_MFR_taf)*264.172/1000000))\n",
    "\n",
    "    # Run da Model again, this time including the MFR\n",
    "    # Executable and control file copies\n",
    "    shutil.copy2(os.path.join(\".\" , 'swb2.exe') ,os.path.join('..', 'output')) \n",
    "    shutil.copy2(os.path.join(\".\" , Control_File_Name) ,os.path.join('..', 'output')) \n",
    "\n",
    "    os.chdir(os.path.join(\"..\", \"output\"))\n",
    "    subprocess.call('swb2.exe {}'.format(Control_File_Name), shell=True)\n",
    "    os.chdir(os.path.join(\"..\", \"run\"))\n",
    "\n",
    "    # Post process the files again, this time with the MFR added \n",
    "    outspace = os.path.join('..', \"output\", 'post_prcessed_with_MFR')\n",
    "    if not os.path.exists(outspace):\n",
    "        os.makedirs(outspace)\n",
    "\n",
    "    # post process the whole model domain\n",
    "    os.chdir(os.path.join(\"..\", 'output'))  # difficulty in making the path to the file so need to change into the output directory\n",
    "    var = []; tot = []; nclist = []\n",
    "\n",
    "    # Step 1: make list of files that you wish to process \n",
    "    for i in Desired_files:\n",
    "        Da_file = create_file_reference(i)\n",
    "        nclist.append(Da_file)\n",
    "\n",
    "    # Step 2 average the daily dimension (len(t) is # of days in the run) to annual \n",
    "    for i, f in enumerate(nclist):\n",
    "        nc_data = nc.Dataset(nclist[i])\n",
    "        nc_attrs, nc_dims, nc_vars = ncdump(nc_data)\n",
    "        nc_var = nc_vars[3]\n",
    "        t = nc_data.variables['time'][:]\n",
    "        y = nc_data.variables['y'][:]\n",
    "        x = nc_data.variables['x'][:]\n",
    "        nt = len(t)\n",
    "        nrow = len(y)\n",
    "        ncol = len(x)\n",
    "        rd = np.zeros((nrow, ncol))  # create 0 array of the proper shape\n",
    "        for day in range(nt):\n",
    "            r_temp = nc_data.variables[str(nc_var)][day, :, :]\n",
    "            r_filled = np.ma.filled(r_temp, fill_value=0)    # fills in missing values with 0s (i think) \n",
    "            rd = rd+r_filled                                 # sequentially add each day's value in each cell to the empty frame  \n",
    "        r = rd/nt*365 # to create a one year average from all the years in model.  if want to add leap years add 0.25 \n",
    "\n",
    "        # step 3: write each yearly average array to a .asc file\n",
    "        keyname = Desired_files[i] \n",
    "        writeArrayToArcGrid(r, os.path.join(outspace, \"{}_annual.asc\".format(keyname)), XLLCORNER, YLLCORNER, CELLSIZE, -999)\n",
    "\n",
    "        # Step 4: calculate total amounts of water in cubic meters per day and create statistics dataframe\n",
    "        m3pd = ((cel_size**2)*r.sum()*.0254)/365 \n",
    "        print(\"{} total  {} [m3/d]\".format(keyname, '%.1f' % m3pd))\n",
    "        var.append(keyname) ; tot.append(m3pd)     # make lists to populate pandas dataframe\n",
    "\n",
    "        nc_data.close()          # make sure to close the nc file so it doesnt stay open\n",
    "\n",
    "    stat_frame = pd.DataFrame({'Variable' : var, 'total_[m3pd]': tot})    #in case you want the max and min#, \"Max_[in]\": mx, \"Min_[in]\":mn})\n",
    "    stat_frame[\"total_[MGD]\"] = stat_frame[\"total_[m3pd]\"]/3785.41178       # put things in MGD if interested, 3785.41178 is number of gal in m3      \n",
    "    Precip = list(stat_frame[stat_frame['Variable'] == 'rainfall']['total_[m3pd]'])[0]   # define the amount of calculated Precip\n",
    "    Dir_net_inf = list(stat_frame[stat_frame['Variable'] == 'direct_net_infiltation']['total_[m3pd]'])[0]   # define the amount of calculated infiltration\n",
    "    WB_ins = Precip + Dir_net_inf\n",
    "    stat_frame['pct_of_pcip'] = stat_frame[\"total_[m3pd]\"]/WB_ins\n",
    "    stat_frame.to_csv(os.path.join(outspace, \"stats_run7_{}m_cells.csv\".format(cel_size)))\n",
    "\n",
    "    # how does the model balance? \n",
    "    print(\"WATER BALANCE ratio: outs over ins water budget balanece =  {} % \".format(stat_frame['pct_of_pcip'].sum()-1))   # check water balance\n",
    "\n",
    "    os.chdir(os.path.join(\"..\", 'run'))  # then back out to the home directory\n",
    "\n",
    "    # calculate statistics for individual watersheds\n",
    "    # note, for some reason will not overwrite csvs need to clear them out or recode to make this issue not an issue\n",
    "    #create workspace\n",
    "    outspace_table = os.path.join('..', 'output', 'post_prcessed_with_MFR', \"tables\")\n",
    "    if not os.path.exists(outspace_table):\n",
    "        os.makedirs(outspace_table)\n",
    "    sheds = (os.path.join(GIS_FOLDER, 'Watersheds\\\\Runoff_zones_sheds_WGS2S_clip.shp'))\n",
    "\n",
    "    # process each raster layer into a table\n",
    "    for i in (os.listdir(outspace)):\n",
    "        if i.endswith('.asc'):\n",
    "            outZSaT = ZonalStatisticsAsTable(sheds, \"SHED_NAME\", os.path.join(outspace, i), os.path.join(outspace_table, \"temptab.dbf\"))  # in arc format\n",
    "            arcpy.TableToTable_conversion(outZSaT, outspace_table, \"Table_{}_1.csv\".format(i))                                            # take table out of stupid arc format and put into csv format \n",
    "\n",
    "    # this block takes each of the csvs, reads them and calculates water volumnes (m3/d) for each watershed\n",
    "    templist = []\n",
    "    for c in (os.listdir(os.path.join(outspace, \"tables\"))):\n",
    "        if c.endswith('.csv'):\n",
    "            data = pd.read_csv(os.path.join(outspace, \"tables\", c))\n",
    "            keyname = c.split(\"Table_\")[1].split(\"_annual\")[0]                   # parameter being worked on\n",
    "            data[keyname] = (data['MEAN']*.0254/365) * data['AREA'] \n",
    "            temp_frame = data[[\"SHED_NAME\", keyname]]\n",
    "            templist.append(temp_frame)\n",
    "\n",
    "    summarry_frame1 = data[['SHED_NAME']]                                        # this is just sticking them all together into one dataframe\n",
    "    for i in templist:\n",
    "        summarry_frame1 = summarry_frame1.merge(i, on ='SHED_NAME', how='outer')\n",
    "\n",
    "\n",
    "    # that was in actual volumns, now to convert each component into a fraction of the rainfall...\n",
    "    templist2 = []\n",
    "    summarry_frame2 = data[['SHED_NAME']]\n",
    "    for i in summarry_frame1.columns[1:]:\n",
    "        temp_frame = data[['SHED_NAME']] ; temp_frame[i.split(\"-\")[0]] = summarry_frame1[i]/summarry_frame1['rainfall']\n",
    "        templist2.append(temp_frame)\n",
    "\n",
    "    summarry_frame3 = data[['SHED_NAME']]\n",
    "    for i in templist2:\n",
    "        summarry_frame3 = summarry_frame3.merge(i, on ='SHED_NAME', how='outer')\n",
    "\n",
    "    summarry_frame_4000 = summarry_frame1.set_index('SHED_NAME')\n",
    "    summarry_frame_4 = summarry_frame_4000.select_dtypes(exclude=['object'])*264.172/1000000   # convert to million gallons per day\n",
    "\n",
    "    summarry_frame3.to_csv(os.path.join(outspace, \"watershed_summary_stats_percentages.csv\"))\n",
    "    summarry_frame1.to_csv(os.path.join(outspace, \"watershed_summary_stats_volume_m3pd.csv\"))\n",
    "    summarry_frame_4.to_csv(os.path.join(outspace, \"watershed_summary_stats_volumes_MGD.csv\"))\n",
    "    \n",
    "    return summarry_frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poop\n",
      "actual_et total  221019.0 [m3/d]\n",
      "direct_net_infiltation total  36247.6 [m3/d]\n",
      "direct_soil_moisture total  1944.4 [m3/d]\n",
      "interception total  127397.1 [m3/d]\n",
      "net_infiltration total  909699.3 [m3/d]\n",
      "rainfall total  1486348.1 [m3/d]\n",
      "runoff total  277173.3 [m3/d]\n",
      "WATER BALANCE ratio: outs over ins water budget balanece =  1.0096134155207488 % \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\arcgis\\pro\\Resources\\ArcToolbox\\Scripts\\AddGeometryAttributes.py:220: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  geom.getArea(\"PRESERVE_SHAPE\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFR leo in MGD is 1.2435263472140021\n",
      "MFR taf in MGD is 5.23504963553931\n",
      "MFR total in MGD is 6.478575982753312\n",
      "actual_et total  221019.0 [m3/d]\n",
      "direct_net_infiltation total  54222.5 [m3/d]\n",
      "direct_soil_moisture total  1944.4 [m3/d]\n",
      "interception total  127397.1 [m3/d]\n",
      "net_infiltration total  927674.3 [m3/d]\n",
      "rainfall total  1486348.1 [m3/d]\n",
      "runoff total  277173.3 [m3/d]\n",
      "WATER BALANCE ratio: outs over ins water budget balanece =  1.0095012487368313 % \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\arcgis\\pro\\Resources\\ArcToolbox\\Scripts\\AddGeometryAttributes.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHED_NAME</th>\n",
       "      <th>actual_et</th>\n",
       "      <th>direct_net_infiltation</th>\n",
       "      <th>direct_soil_moisture</th>\n",
       "      <th>interception</th>\n",
       "      <th>net_infiltration</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>runoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fagatuitui - Vaaogeoge</td>\n",
       "      <td>4284.047507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6655.140987</td>\n",
       "      <td>35491.663567</td>\n",
       "      <td>54583.048093</td>\n",
       "      <td>9635.006361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vatia</td>\n",
       "      <td>5117.028339</td>\n",
       "      <td>518.633198</td>\n",
       "      <td>37.578082</td>\n",
       "      <td>5953.022336</td>\n",
       "      <td>34942.077169</td>\n",
       "      <td>54466.799730</td>\n",
       "      <td>10293.590099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tula</td>\n",
       "      <td>2305.415338</td>\n",
       "      <td>503.017415</td>\n",
       "      <td>12.526027</td>\n",
       "      <td>1124.294465</td>\n",
       "      <td>5219.943557</td>\n",
       "      <td>8945.615566</td>\n",
       "      <td>847.371835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Onenoa</td>\n",
       "      <td>1194.530685</td>\n",
       "      <td>153.388161</td>\n",
       "      <td>8.350685</td>\n",
       "      <td>836.585534</td>\n",
       "      <td>3338.631672</td>\n",
       "      <td>5584.179574</td>\n",
       "      <td>436.065810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afono</td>\n",
       "      <td>3839.505750</td>\n",
       "      <td>377.569253</td>\n",
       "      <td>12.526027</td>\n",
       "      <td>3122.147129</td>\n",
       "      <td>24460.506186</td>\n",
       "      <td>36551.240160</td>\n",
       "      <td>6381.252427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Masefau</td>\n",
       "      <td>3878.914030</td>\n",
       "      <td>795.722834</td>\n",
       "      <td>4.175342</td>\n",
       "      <td>3550.794745</td>\n",
       "      <td>22293.934900</td>\n",
       "      <td>33484.089385</td>\n",
       "      <td>5160.806813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aoa</td>\n",
       "      <td>2715.225206</td>\n",
       "      <td>366.699449</td>\n",
       "      <td>8.350685</td>\n",
       "      <td>1823.358139</td>\n",
       "      <td>8390.455062</td>\n",
       "      <td>13876.068710</td>\n",
       "      <td>1480.583391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Masausi</td>\n",
       "      <td>1779.336118</td>\n",
       "      <td>470.769852</td>\n",
       "      <td>8.350685</td>\n",
       "      <td>1604.646740</td>\n",
       "      <td>7487.599901</td>\n",
       "      <td>11434.947808</td>\n",
       "      <td>1146.249809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sailele</td>\n",
       "      <td>622.146905</td>\n",
       "      <td>181.425586</td>\n",
       "      <td>8.350685</td>\n",
       "      <td>525.327672</td>\n",
       "      <td>2340.369916</td>\n",
       "      <td>3759.262644</td>\n",
       "      <td>458.717039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alao</td>\n",
       "      <td>2029.912329</td>\n",
       "      <td>482.252044</td>\n",
       "      <td>8.350685</td>\n",
       "      <td>1205.198686</td>\n",
       "      <td>5288.683622</td>\n",
       "      <td>8703.209081</td>\n",
       "      <td>637.693096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pago Pago Harbor</td>\n",
       "      <td>14695.180436</td>\n",
       "      <td>4093.477839</td>\n",
       "      <td>334.027397</td>\n",
       "      <td>9106.581974</td>\n",
       "      <td>80330.186158</td>\n",
       "      <td>130842.567695</td>\n",
       "      <td>29912.828494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fagaitua</td>\n",
       "      <td>6112.673535</td>\n",
       "      <td>1295.546115</td>\n",
       "      <td>29.227397</td>\n",
       "      <td>5385.099232</td>\n",
       "      <td>28469.057657</td>\n",
       "      <td>43172.206061</td>\n",
       "      <td>4583.746623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Auasi</td>\n",
       "      <td>1208.246684</td>\n",
       "      <td>192.086626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>850.517263</td>\n",
       "      <td>3394.810911</td>\n",
       "      <td>5668.577141</td>\n",
       "      <td>427.214084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Amouli</td>\n",
       "      <td>2784.334088</td>\n",
       "      <td>612.460100</td>\n",
       "      <td>4.175342</td>\n",
       "      <td>1664.221918</td>\n",
       "      <td>7417.802087</td>\n",
       "      <td>12140.531956</td>\n",
       "      <td>938.025478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alega</td>\n",
       "      <td>1337.584871</td>\n",
       "      <td>113.325751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1587.882743</td>\n",
       "      <td>9748.617443</td>\n",
       "      <td>14522.676168</td>\n",
       "      <td>2172.291512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Laulii - Aumi</td>\n",
       "      <td>3504.385806</td>\n",
       "      <td>279.316490</td>\n",
       "      <td>16.701370</td>\n",
       "      <td>2610.612000</td>\n",
       "      <td>18482.174358</td>\n",
       "      <td>29146.973254</td>\n",
       "      <td>5118.628881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fagasa</td>\n",
       "      <td>3829.763286</td>\n",
       "      <td>514.520487</td>\n",
       "      <td>41.753425</td>\n",
       "      <td>3242.877144</td>\n",
       "      <td>28189.212308</td>\n",
       "      <td>44422.129661</td>\n",
       "      <td>10587.513309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aasu</td>\n",
       "      <td>9686.084719</td>\n",
       "      <td>556.072098</td>\n",
       "      <td>12.526027</td>\n",
       "      <td>10109.380951</td>\n",
       "      <td>69270.357991</td>\n",
       "      <td>107370.810462</td>\n",
       "      <td>21148.053922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fagaalu</td>\n",
       "      <td>2911.334078</td>\n",
       "      <td>538.981030</td>\n",
       "      <td>45.928767</td>\n",
       "      <td>2500.953585</td>\n",
       "      <td>18984.106143</td>\n",
       "      <td>30995.814878</td>\n",
       "      <td>7555.845852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Aoloau Sisifo</td>\n",
       "      <td>1542.949096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2191.484158</td>\n",
       "      <td>11328.657473</td>\n",
       "      <td>17692.818808</td>\n",
       "      <td>3061.862135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Aoloau Sasae</td>\n",
       "      <td>5500.714476</td>\n",
       "      <td>71.704547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6982.299947</td>\n",
       "      <td>44439.805130</td>\n",
       "      <td>68592.038864</td>\n",
       "      <td>13430.977232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fagamalo</td>\n",
       "      <td>2240.259122</td>\n",
       "      <td>150.277531</td>\n",
       "      <td>4.175342</td>\n",
       "      <td>2736.032323</td>\n",
       "      <td>14943.084442</td>\n",
       "      <td>22704.614571</td>\n",
       "      <td>3294.894954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Matuu - Faganeanea</td>\n",
       "      <td>2898.140007</td>\n",
       "      <td>344.931994</td>\n",
       "      <td>29.227397</td>\n",
       "      <td>3122.836046</td>\n",
       "      <td>20563.095361</td>\n",
       "      <td>32492.744724</td>\n",
       "      <td>6402.261360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nuuuli Pala</td>\n",
       "      <td>30890.234373</td>\n",
       "      <td>16762.545580</td>\n",
       "      <td>597.073973</td>\n",
       "      <td>13595.548335</td>\n",
       "      <td>135125.132888</td>\n",
       "      <td>207537.533724</td>\n",
       "      <td>44361.496641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Maloata</td>\n",
       "      <td>2985.300274</td>\n",
       "      <td>309.017089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4009.769272</td>\n",
       "      <td>23406.886364</td>\n",
       "      <td>35638.287799</td>\n",
       "      <td>6565.099707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Fagalii</td>\n",
       "      <td>2549.234470</td>\n",
       "      <td>535.752098</td>\n",
       "      <td>8.350685</td>\n",
       "      <td>2620.131789</td>\n",
       "      <td>12834.376466</td>\n",
       "      <td>19922.180346</td>\n",
       "      <td>2864.208388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Afao - Asili</td>\n",
       "      <td>3367.866028</td>\n",
       "      <td>152.212107</td>\n",
       "      <td>4.175342</td>\n",
       "      <td>3783.396111</td>\n",
       "      <td>22415.541741</td>\n",
       "      <td>34586.811202</td>\n",
       "      <td>5686.635498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Leone</td>\n",
       "      <td>31750.097449</td>\n",
       "      <td>8142.620568</td>\n",
       "      <td>66.805479</td>\n",
       "      <td>10962.549540</td>\n",
       "      <td>98237.854261</td>\n",
       "      <td>159079.204999</td>\n",
       "      <td>28344.743788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Poloa</td>\n",
       "      <td>1473.777588</td>\n",
       "      <td>451.611989</td>\n",
       "      <td>8.350685</td>\n",
       "      <td>1294.446628</td>\n",
       "      <td>5854.219837</td>\n",
       "      <td>9156.679135</td>\n",
       "      <td>1095.401097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nua - Seetaga</td>\n",
       "      <td>4012.733766</td>\n",
       "      <td>186.943998</td>\n",
       "      <td>4.175342</td>\n",
       "      <td>4319.823239</td>\n",
       "      <td>20714.549010</td>\n",
       "      <td>33078.419966</td>\n",
       "      <td>4453.642952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Tafuna Plain</td>\n",
       "      <td>44528.969670</td>\n",
       "      <td>11693.749282</td>\n",
       "      <td>463.463014</td>\n",
       "      <td>2869.524983</td>\n",
       "      <td>72846.156180</td>\n",
       "      <td>134818.969038</td>\n",
       "      <td>24697.707427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amanave</td>\n",
       "      <td>1572.197371</td>\n",
       "      <td>203.534024</td>\n",
       "      <td>12.526027</td>\n",
       "      <td>1286.986680</td>\n",
       "      <td>5472.113385</td>\n",
       "      <td>8940.215417</td>\n",
       "      <td>859.139343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Fagatele - Larsen</td>\n",
       "      <td>6391.001874</td>\n",
       "      <td>377.861527</td>\n",
       "      <td>4.175342</td>\n",
       "      <td>3136.746907</td>\n",
       "      <td>14703.350186</td>\n",
       "      <td>27454.198921</td>\n",
       "      <td>3756.339891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SHED_NAME     actual_et  direct_net_infiltation  \\\n",
       "0   Fagatuitui - Vaaogeoge   4284.047507                0.000000   \n",
       "1                    Vatia   5117.028339              518.633198   \n",
       "2                     Tula   2305.415338              503.017415   \n",
       "3                   Onenoa   1194.530685              153.388161   \n",
       "4                    Afono   3839.505750              377.569253   \n",
       "5                  Masefau   3878.914030              795.722834   \n",
       "6                      Aoa   2715.225206              366.699449   \n",
       "7                  Masausi   1779.336118              470.769852   \n",
       "8                  Sailele    622.146905              181.425586   \n",
       "9                     Alao   2029.912329              482.252044   \n",
       "10        Pago Pago Harbor  14695.180436             4093.477839   \n",
       "11                Fagaitua   6112.673535             1295.546115   \n",
       "12                   Auasi   1208.246684              192.086626   \n",
       "13                  Amouli   2784.334088              612.460100   \n",
       "14                   Alega   1337.584871              113.325751   \n",
       "15           Laulii - Aumi   3504.385806              279.316490   \n",
       "16                  Fagasa   3829.763286              514.520487   \n",
       "17                    Aasu   9686.084719              556.072098   \n",
       "18                 Fagaalu   2911.334078              538.981030   \n",
       "19           Aoloau Sisifo   1542.949096                0.000000   \n",
       "20            Aoloau Sasae   5500.714476               71.704547   \n",
       "21                Fagamalo   2240.259122              150.277531   \n",
       "22      Matuu - Faganeanea   2898.140007              344.931994   \n",
       "23             Nuuuli Pala  30890.234373            16762.545580   \n",
       "24                 Maloata   2985.300274              309.017089   \n",
       "25                 Fagalii   2549.234470              535.752098   \n",
       "26            Afao - Asili   3367.866028              152.212107   \n",
       "27                   Leone  31750.097449             8142.620568   \n",
       "28                   Poloa   1473.777588              451.611989   \n",
       "29           Nua - Seetaga   4012.733766              186.943998   \n",
       "30            Tafuna Plain  44528.969670            11693.749282   \n",
       "31                 Amanave   1572.197371              203.534024   \n",
       "32       Fagatele - Larsen   6391.001874              377.861527   \n",
       "\n",
       "    direct_soil_moisture  interception  net_infiltration       rainfall  \\\n",
       "0               0.000000   6655.140987      35491.663567   54583.048093   \n",
       "1              37.578082   5953.022336      34942.077169   54466.799730   \n",
       "2              12.526027   1124.294465       5219.943557    8945.615566   \n",
       "3               8.350685    836.585534       3338.631672    5584.179574   \n",
       "4              12.526027   3122.147129      24460.506186   36551.240160   \n",
       "5               4.175342   3550.794745      22293.934900   33484.089385   \n",
       "6               8.350685   1823.358139       8390.455062   13876.068710   \n",
       "7               8.350685   1604.646740       7487.599901   11434.947808   \n",
       "8               8.350685    525.327672       2340.369916    3759.262644   \n",
       "9               8.350685   1205.198686       5288.683622    8703.209081   \n",
       "10            334.027397   9106.581974      80330.186158  130842.567695   \n",
       "11             29.227397   5385.099232      28469.057657   43172.206061   \n",
       "12              0.000000    850.517263       3394.810911    5668.577141   \n",
       "13              4.175342   1664.221918       7417.802087   12140.531956   \n",
       "14              0.000000   1587.882743       9748.617443   14522.676168   \n",
       "15             16.701370   2610.612000      18482.174358   29146.973254   \n",
       "16             41.753425   3242.877144      28189.212308   44422.129661   \n",
       "17             12.526027  10109.380951      69270.357991  107370.810462   \n",
       "18             45.928767   2500.953585      18984.106143   30995.814878   \n",
       "19              0.000000   2191.484158      11328.657473   17692.818808   \n",
       "20              0.000000   6982.299947      44439.805130   68592.038864   \n",
       "21              4.175342   2736.032323      14943.084442   22704.614571   \n",
       "22             29.227397   3122.836046      20563.095361   32492.744724   \n",
       "23            597.073973  13595.548335     135125.132888  207537.533724   \n",
       "24              0.000000   4009.769272      23406.886364   35638.287799   \n",
       "25              8.350685   2620.131789      12834.376466   19922.180346   \n",
       "26              4.175342   3783.396111      22415.541741   34586.811202   \n",
       "27             66.805479  10962.549540      98237.854261  159079.204999   \n",
       "28              8.350685   1294.446628       5854.219837    9156.679135   \n",
       "29              4.175342   4319.823239      20714.549010   33078.419966   \n",
       "30            463.463014   2869.524983      72846.156180  134818.969038   \n",
       "31             12.526027   1286.986680       5472.113385    8940.215417   \n",
       "32              4.175342   3136.746907      14703.350186   27454.198921   \n",
       "\n",
       "          runoff  \n",
       "0    9635.006361  \n",
       "1   10293.590099  \n",
       "2     847.371835  \n",
       "3     436.065810  \n",
       "4    6381.252427  \n",
       "5    5160.806813  \n",
       "6    1480.583391  \n",
       "7    1146.249809  \n",
       "8     458.717039  \n",
       "9     637.693096  \n",
       "10  29912.828494  \n",
       "11   4583.746623  \n",
       "12    427.214084  \n",
       "13    938.025478  \n",
       "14   2172.291512  \n",
       "15   5118.628881  \n",
       "16  10587.513309  \n",
       "17  21148.053922  \n",
       "18   7555.845852  \n",
       "19   3061.862135  \n",
       "20  13430.977232  \n",
       "21   3294.894954  \n",
       "22   6402.261360  \n",
       "23  44361.496641  \n",
       "24   6565.099707  \n",
       "25   2864.208388  \n",
       "26   5686.635498  \n",
       "27  28344.743788  \n",
       "28   1095.401097  \n",
       "29   4453.642952  \n",
       "30  24697.707427  \n",
       "31    859.139343  \n",
       "32   3756.339891  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(\"poop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Results = os.path.join('..', \"Workspace\", 'SWB2_results')\n",
    "if not os.path.exists(Results):\n",
    "    os.makedirs(Results)\n",
    "    \n",
    "Results_table = os.path.join(Results, \"tables\")\n",
    "if not os.path.exists(Results_table):\n",
    "    os.makedirs(Results_table)\n",
    "    \n",
    "# process each raster layer into a table of annual statistics  \n",
    "\"\"\" note this is where need to modify to process into monthly statistics \"\"\"\n",
    "for i in (os.listdir(SWB_asc_files)):\n",
    "    if i.endswith('.asc'):\n",
    "        outZSaT = ZonalStatisticsAsTable(sheds, \"Uniqe_ID\", os.path.join(SWB_asc_files, i), os.path.join(Results_table, \"temptab.dbf\"))  # in arc format\n",
    "        arcpy.TableToTable_conversion(outZSaT, Results_table, \"Table_{}_1.csv\".format(i)) \n",
    "\n",
    "# this block takes the parameters of interests, reads them and calculates water volumnes (m3/d) for each watershed\n",
    "\n",
    "templist = []\n",
    "intrest_list = ['Table_netinfiltration_annual.asc_1.csv', 'Table_runoff_annual.asc_1.csv', 'Table_rainfall_annual.asc_1.csv'] \n",
    "for c in intrest_list:\n",
    "    data = pd.read_csv(os.path.join(Results_table, c))\n",
    "    keyname = c.split(\"Table_\")[1].split(\"_annual\")[0]                   # parameter being worked on\n",
    "    data[keyname] = (data['MEAN']*.0254/365) * data['AREA'] \n",
    "    temp_frame = data[[\"Uniqe_ID\", keyname]]\n",
    "    templist.append(temp_frame)\n",
    "        \n",
    "summarry_frame1 = data[['Uniqe_ID']]                                        # this is just sticking them all together into one dataframe\n",
    "for i in templist:\n",
    "    summarry_frame1 = summarry_frame1.merge(i, on ='Uniqe_ID', how='outer')\n",
    "    \n",
    "summarry_frame1 = summarry_frame1[summarry_frame1.netinfiltration != 0]   # some of the values turned out tot be 0, this just selects rows that have non-zero values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
